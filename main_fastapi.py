# main_fastapi.py
# Versi√≥n estable Twilio ‚Üî OpenAI Realtime (oct 2025)
# - Œº-law 8 kHz end-to-end (sin resampling)
# - Server VAD (turn_detection) en OpenAI
# - Env√≠o con temporizaci√≥n (20 ms) hacia Twilio para evitar audio entrecortado
# - Reenv√≠o de streamSid en los eventos "media" hacia Twilio
# - Respuestas creadas autom√°ticamente al detectar fin de habla (speech_stopped)

import os
import json
import base64
import asyncio
import websockets
from fastapi import FastAPI, WebSocket, Request
from fastapi.responses import Response, PlainTextResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.websockets import WebSocketState

# ===== CONFIG =====
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
PORT_ENV = os.getenv("PORT")
PORT = int(PORT_ENV) if PORT_ENV else 8080

print(f"üß© DEBUG OPENAI_API_KEY: {OPENAI_API_KEY[:10]}...")
print(f"üß© Using PORT: {PORT}")

VOICE = "alloy"  # Puedes cambiar la voz si tu cuenta lo permite

app = FastAPI(title="In Houston AI ‚Äî Twilio Realtime Bridge")

# CORS para Twilio
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== Health =====
@app.get("/")
async def root():
    return PlainTextResponse("‚úÖ In Houston AI ‚Äî FastAPI listo para Twilio Realtime")

# ===== TwiML (recibe la llamada y conecta Media Stream) =====
@app.post("/twiml")
async def twiml_webhook(request: Request):
    host = request.url.hostname or "inhouston-ai-api.onrender.com"
    xml = f"""<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Connect>
    <Stream url="wss://{host}/media" />
  </Connect>
</Response>"""
    return Response(content=xml.strip(), media_type="application/xml")

# ===== Utilidades =====
def ulaw_silence_b64(ms: int = 20) -> str:
    """Frame de silencio Œº-law 8k (20 ms). Œº-law silencio = 0xFF."""
    samples = 8_000 * ms // 1000
    return base64.b64encode(b"\xFF" * samples).decode("utf-8")

# ===== WebSocket principal (Twilio <-> OpenAI) =====
@app.websocket("/media")
async def media_socket(websocket: WebSocket):
    await websocket.accept()
    print("üü¢ [Twilio] WebSocket /media ACCEPTED")

    if not OPENAI_API_KEY:
        print("‚ùå Falta OPENAI_API_KEY en variables de entorno")
        await websocket.close()
        return

    realtime_uri = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "OpenAI-Beta": "realtime=v1",
    }

    stream_sid: str | None = None

    # Cola de salida para Twilio (Œº-law b64) y emisor ritmado (20 ms)
    outbound_queue: asyncio.Queue[str] = asyncio.Queue()

    async def _twilio_send_ulaw_b64(ulaw_b64: str):
        """Env√≠a un frame Œº-law a Twilio (con streamSid si est√° disponible)."""
        if websocket.application_state != WebSocketState.CONNECTED:
            return
        payload = {
            "event": "media",
            "media": {"payload": ulaw_b64},
        }
        if stream_sid:
            payload["streamSid"] = stream_sid
        try:
            await websocket.send_text(json.dumps(payload))
        except Exception as e:
            print(f"‚ö†Ô∏è [Twilio] env√≠o fallido: {e}")

    async def paced_sender():
        """
        Consumidor de la cola de salida que env√≠a a Twilio a ~20 ms por frame.
        Si la cola se queda vac√≠a por >60 ms, env√≠a un silencio de 20 ms (keepalive).
        """
        SILENCE_20 = ulaw_silence_b64(20)
        while websocket.application_state == WebSocketState.CONNECTED:
            try:
                # Espera un frame hasta 60 ms; si no hay, manda silencio
                b64 = await asyncio.wait_for(outbound_queue.get(), timeout=0.06)
                await _twilio_send_ulaw_b64(b64)
                # Ritmo objetivo ~20 ms
                await asyncio.sleep(0.02)
            except asyncio.TimeoutError:
                # Mantiene viva la llamada y el jitter buffer de Twilio estable
                await _twilio_send_ulaw_b64(SILENCE_20)

    try:
        async with websockets.connect(
            realtime_uri,
            extra_headers=headers,
            subprotocols=["realtime"],
            ping_interval=20,
            ping_timeout=20,
            close_timeout=5,
            max_size=10_000_000,
        ) as openai_ws:
            print("üîó [OpenAI] Realtime CONNECTED")

            # ---- Configurar sesi√≥n: Œº-law end-to-end + VAD + voz + sistema ----
            session_update = {
                "type": "session.update",
                "session": {
                    "turn_detection": {"type": "server_vad"},
                    "input_audio_format": "g711_ulaw",
                    "output_audio_format": "g711_ulaw",
                    "voice": VOICE,
                    "modalities": ["text", "audio"],
                    "instructions": (
                        "Eres el asistente de voz de In Houston Texas. "
                        "Habla en espa√±ol latino, c√°lido y profesional. "
                        "Saluda breve y pregunta c√≥mo puedes ayudar."
                    ),
                    "temperature": 0.8,
                }
            }
            print("‚û°Ô∏è  [OpenAI] session.update")
            await openai_ws.send(json.dumps(session_update))

            # (Opcional) Saludo inicial inmediato:
            await openai_ws.send(json.dumps({"type": "response.create"}))

            # Lanzamos el emisor ritmado hacia Twilio
            sender_task = asyncio.create_task(paced_sender())

            # ---- Twilio -> OpenAI (Œº-law directo) ----
            async def twilio_to_openai():
                nonlocal stream_sid
                try:
                    while True:
                        msg_txt = await websocket.receive_text()
                        data = json.loads(msg_txt)
                        ev = data.get("event")

                        if ev == "start":
                            stream_sid = data.get("start", {}).get("streamSid")
                            print(f"üéß [Twilio] stream START sid={stream_sid}")

                        elif ev == "media":
                            # Œº-law base64 tal cual hacia OpenAI
                            ulaw_b64 = data["media"]["payload"]
                            await openai_ws.send(json.dumps({
                                "type": "input_audio_buffer.append",
                                "audio": ulaw_b64  # g711_ulaw base64
                            }))

                        elif ev == "mark":
                            # Marca de Twilio para fin de un bloque reproducido (opcional)
                            pass

                        elif ev == "stop":
                            print("üõë [Twilio] stream STOP (fin de la llamada)")
                            try:
                                await openai_ws.close()
                            except Exception:
                                pass
                            break
                except Exception as e:
                    print(f"‚ö†Ô∏è [Twilio‚ÜíOpenAI] Error: {e}")

            # ---- OpenAI -> Twilio ----
            async def openai_to_twilio():
                try:
                    async for raw in openai_ws:
                        try:
                            evt = json.loads(raw)
                        except Exception:
                            continue

                        t = evt.get("type")

                        # Logs √∫tiles
                        if t and t not in ("response.audio.delta", "response.output_audio.delta",
                                           "input_audio_buffer.speech_started", "input_audio_buffer.speech_stopped"):
                            print(f"‚ÑπÔ∏è [OpenAI] {t}")

                        # Al detectar fin de habla: commit + pedir respuesta
                        if t == "input_audio_buffer.speech_stopped":
                            await openai_ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
                            await openai_ws.send(json.dumps({"type": "response.create"}))

                        # Audio saliente (los nombres pueden variar por release)
                        if t in ("response.audio.delta", "response.output_audio.delta"):
                            # Campo puede ser 'delta' (nuevo) o 'audio' (algunas previews)
                            audio_b64 = evt.get("delta") or evt.get("audio")
                            if not audio_b64:
                                continue
                            # Encolamos el frame para que el sender lo pacee a 20 ms
                            await outbound_queue.put(audio_b64)

                except Exception as e:
                    print(f"‚ö†Ô∏è [OpenAI‚ÜíTwilio] Error: {e}")

            await asyncio.gather(twilio_to_openai(), openai_to_twilio())

            # Cerrar emisor ritmado
            if not sender_task.done():
                sender_task.cancel()
                try:
                    await sender_task
                except asyncio.CancelledError:
                    pass

    except Exception as e:
        import traceback
        print("‚ùå [OpenAI] Fallo al conectar:", e)
        traceback.print_exc()
    finally:
        print("üî¥ [Twilio] WebSocket CLOSED")

# ===== Local debug =====
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main_fastapi:app", host="0.0.0.0", port=PORT, reload=True)
