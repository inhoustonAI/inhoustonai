# main_fastapi.py ‚Äî Multibot Twilio ‚Üî OpenAI Realtime (Oct 2025)
# - Un tel√©fono = un bot (estricto opcional)
# - Lee voz/temperatura/saludo/prompt/modelo desde bots/<slug>.json
# - Œº-law 8 kHz end-to-end, VAD server y pacing ~20 ms
# - Logs de diagn√≥stico: ruta del JSON y resumen de claves

import os, json, base64, asyncio, websockets
from pathlib import Path
from typing import Optional, Dict, Any

from fastapi import FastAPI, WebSocket, Request
from fastapi.responses import Response, PlainTextResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.websockets import WebSocketState

# ===== CONFIG GLOBAL =====
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
PORT = int(os.getenv("PORT", "8080"))

# Carpeta con los JSON de bots (relativa a la ra√≠z del repo en Render)
BOTS_DIR = Path(os.getenv("BOTS_DIR", "bots")).resolve()

# Enrutado por n√∫mero: { "+18326213202": "sundin", ... }
try:
    TWILIO_BOT_MAP: Dict[str, str] = json.loads(os.getenv("TWILIO_BOT_MAP", "{}"))
except Exception:
    TWILIO_BOT_MAP = {}

# Estricto: si el n√∫mero no est√° en el mapa y no hay ?bot= ‚Üí cuelga (sin fallback)
ROUTING_STRICT = os.getenv("ROUTING_STRICT", "1").lower() in ("1", "true", "yes")

# Permitir forzar bot con query ?bot= (√∫til en pruebas)
ALLOW_QUERY_OVERRIDE = os.getenv("ALLOW_QUERY_OVERRIDE", "1").lower() in ("1", "true", "yes")

print(f"üß© BASE DIR: {Path.cwd()}")
print(f"üß© BOTS_DIR: {BOTS_DIR} (exists={BOTS_DIR.exists()})")
print(f"üß© TWILIO_BOT_MAP: {TWILIO_BOT_MAP}")
print(f"üß© ROUTING_STRICT={ROUTING_STRICT}  ALLOW_QUERY_OVERRIDE={ALLOW_QUERY_OVERRIDE}")

app = FastAPI(title="In Houston AI ‚Äî Twilio Realtime Bridge (Multibot)")

# CORS para Twilio
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== Utilidades de audio =====
def ulaw_silence_b64(ms: int = 20) -> str:
    """Frame de silencio Œº-law 8k (20 ms). Œº-law silencio = 0xFF."""
    samples = 8_000 * ms // 1000
    return base64.b64encode(b"\xFF" * samples).decode("utf-8")

# ===== Utilidades de bots (JSON) =====
_JSON_CACHE: Dict[str, Dict[str, Any]] = {}

def _load_bot_json(slug: str) -> Optional[Dict[str, Any]]:
    """
    Carga bots/<slug>.json desde BOTS_DIR.
    Acepta alias: greeting->first_message, instructions->system_prompt.
    Imprime ruta y resumen para diagn√≥stico.
    """
    slug = (slug or "").strip().lower()
    if not slug:
        print("‚ùå [CFG] slug vac√≠o")
        return None
    if slug in _JSON_CACHE:
        return _JSON_CACHE[slug]

    path = BOTS_DIR / f"{slug}.json"
    print(f"üîé [CFG] Intentando cargar: {path.resolve()}")
    if not path.exists():
        print(f"‚ùå [CFG] NO existe: {path.resolve()}")
        return None

    try:
        with path.open("r", encoding="utf-8") as f:
            cfg = json.load(f)
    except Exception as e:
        print(f"‚ùå [CFG] JSON inv√°lido en {path.resolve()}: {e}")
        return None

    # Alias de compatibilidad
    if "first_message" not in cfg and "greeting" in cfg:
        cfg["first_message"] = cfg.get("greeting")
    if "system_prompt" not in cfg and "instructions" in cfg:
        cfg["system_prompt"] = cfg.get("instructions")

    # Defaults razonables
    cfg.setdefault("voice", "alloy")
    cfg.setdefault("temperature", 0.8)
    cfg.setdefault("first_message", "")
    cfg.setdefault("system_prompt", "")
    cfg.setdefault("model", "gpt-4o-realtime-preview")

    # Log de resumen (80 chars m√°x)
    fm = (cfg.get("first_message") or "")[:80]
    sp = (cfg.get("system_prompt") or "")[:80]
    print(f"‚úÖ [CFG] Cargado {slug}.json | voice={cfg.get('voice')} temp={cfg.get('temperature')} model={cfg.get('model')}")
    print(f"üìù [CFG] first_message: {fm!r}")
    print(f"üìù [CFG] system_prompt: {sp!r}")

    _JSON_CACHE[slug] = cfg
    return cfg

async def _resolve_bot_slug_from_twilio(request: Request) -> Optional[str]:
    """
    Prioridad:
      1) query ?bot=slug (si ALLOW_QUERY_OVERRIDE=1)
      2) map por n√∫mero To (TWILIO_BOT_MAP)
      3) si ROUTING_STRICT=1 ‚Üí None (mensaje y cuelga), si no ‚Üí None (sin usar)
    """
    # 1) query
    if ALLOW_QUERY_OVERRIDE:
        q = dict(request.query_params)
        if "bot" in q and q["bot"].strip():
            return q["bot"].strip().lower()

    # 2) cuerpo Twilio (form-urlencoded)
    try:
        form = await request.form()
        to_number = (form.get("To") or form.get("Called") or "").strip()
        if to_number:
            print(f"‚òéÔ∏è  [Twilio] To={to_number}")
        if to_number and to_number in TWILIO_BOT_MAP:
            return TWILIO_BOT_MAP[to_number].strip().lower()
    except Exception as e:
        print(f"‚ö†Ô∏è [Twilio] No se pudo leer form: {e}")

    # 3) estricto ‚Üí None (para devolver TwiML de error)
    return None

# ===== Health =====
@app.get("/")
async def root():
    return PlainTextResponse("‚úÖ In Houston AI ‚Äî FastAPI multibot (Strict-ready) listo para Twilio Realtime")

# ===== TwiML (recibe la llamada y conecta Media Stream) =====
@app.post("/twiml")
async def twiml_webhook(request: Request):
    host = request.url.hostname or "inhouston-ai-api.onrender.com"
    slug = await _resolve_bot_slug_from_twilio(request)

    if not slug:
        if ROUTING_STRICT:
            # Enrutado estricto: n√∫mero no mapeado ‚Üí mensaje y cuelga
            xml = """<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say language="es-MX">Este n√∫mero no est√° configurado para un bot. Contacte al administrador.</Say>
  <Hangup/>
</Response>"""
            return Response(content=xml.strip(), media_type="application/xml")
        else:
            # Modo no estricto: usa un fallback "demo"
            slug = "default"

    # Cargar JSON aqu√≠ para fallar pronto si no existe
    cfg = _load_bot_json(slug)
    if not cfg:
        xml = f"""<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say language="es-MX">No se encontr√≥ configuraci√≥n para el bot {slug}. Revise la carpeta de bots.</Say>
  <Hangup/>
</Response>"""
        return Response(content=xml.strip(), media_type="application/xml")

    # Pasamos el slug a /media por query
    xml = f"""<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Connect>
    <Stream url="wss://{host}/media?bot={slug}" />
  </Connect>
</Response>"""
    return Response(content=xml.strip(), media_type="application/xml")

# ===== WebSocket principal (Twilio <-> OpenAI) =====
@app.websocket("/media")
async def media_socket(websocket: WebSocket):
    await websocket.accept()
    print("üü¢ [Twilio] WebSocket /media ACCEPTED")

    if not OPENAI_API_KEY:
        print("‚ùå Falta OPENAI_API_KEY en variables de entorno")
        await websocket.close()
        return

    # Resolvemos el bot por query param en el WS (viene de /twiml)
    q = dict(websocket.query_params)
    bot_slug = (q.get("bot") or "").strip().lower()
    cfg = _load_bot_json(bot_slug)
    if not cfg:
        print(f"‚ùå Bot JSON no encontrado para slug={bot_slug}")
        await websocket.close()
        return

    voice = cfg.get("voice", "alloy")
    temperature = float(cfg.get("temperature", 0.8))
    system_prompt = (cfg.get("system_prompt") or "").strip()
    first_message = (cfg.get("first_message") or "").strip()
    model = (cfg.get("model") or "gpt-4o-realtime-preview").strip()

    print(f"ü§ñ [BOT] slug={bot_slug} voice={voice} temp={temperature} model={model}")

    realtime_uri = f"wss://api.openai.com/v1/realtime?model={model}"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "OpenAI-Beta": "realtime=v1",
    }

    stream_sid: Optional[str] = None

    # Cola de salida para Twilio (Œº-law b64) y emisor ritmado (20 ms)
    outbound_queue: asyncio.Queue[str] = asyncio.Queue()

    async def _twilio_send_ulaw_b64(ulaw_b64: str):
        """Env√≠a un frame Œº-law a Twilio (con streamSid si est√° disponible)."""
        if websocket.application_state != WebSocketState.CONNECTED:
            return
        payload = {
            "event": "media",
            "media": {"payload": ulaw_b64},
        }
        if stream_sid:
            payload["streamSid"] = stream_sid
        try:
            await websocket.send_text(json.dumps(payload))
        except Exception as e:
            print(f"‚ö†Ô∏è [Twilio] env√≠o fallido: {e}")

    async def paced_sender():
        """
        Consumidor de la cola de salida que env√≠a a Twilio a ~20 ms por frame.
        Si la cola se queda vac√≠a por >60 ms, env√≠a un silencio de 20 ms (keepalive).
        """
        SILENCE_20 = ulaw_silence_b64(20)
        while websocket.application_state == WebSocketState.CONNECTED:
            try:
                b64 = await asyncio.wait_for(outbound_queue.get(), timeout=0.06)
                await _twilio_send_ulaw_b64(b64)
                await asyncio.sleep(0.02)
            except asyncio.TimeoutError:
                await _twilio_send_ulaw_b64(SILENCE_20)

    try:
        async with websockets.connect(
            realtime_uri,
            extra_headers=headers,
            subprotocols=["realtime"],
            ping_interval=20,
            ping_timeout=20,
            close_timeout=5,
            max_size=10_000_000,
        ) as openai_ws:
            print("üîó [OpenAI] Realtime CONNECTED")

            # ---- Configurar sesi√≥n con par√°metros del JSON ----
            session_update = {
                "type": "session.update",
                "session": {
                    "turn_detection": {"type": "server_vad"},
                    "input_audio_format": "g711_ulaw",
                    "output_audio_format": "g711_ulaw",
                    "voice": voice,
                    "modalities": ["text", "audio"],
                    "instructions": system_prompt or (
                        "Eres un asistente de voz en espa√±ol latino. "
                        "Saluda breve, s√© √∫til, agenda citas cuando aplique."
                    ),
                    "temperature": float(temperature),
                }
            }
            print(f"‚û°Ô∏è  [OpenAI] session.update (voice={voice}, temp={temperature})")
            await openai_ws.send(json.dumps(session_update))

            # (Opcional) Saludo inicial controlado por JSON:
            if first_message:
                await openai_ws.send(json.dumps({
                    "type": "response.create",
                    "response": {"instructions": first_message}
                }))
            else:
                await openai_ws.send(json.dumps({"type": "response.create"}))

            # Lanzamos el emisor ritmado hacia Twilio
            sender_task = asyncio.create_task(paced_sender())

            # ---- Twilio -> OpenAI (Œº-law directo) ----
            async def twilio_to_openai():
                nonlocal stream_sid
                try:
                    while True:
                        msg_txt = await websocket.receive_text()
                        data = json.loads(msg_txt)
                        ev = data.get("event")

                        if ev == "start":
                            stream_sid = data.get("start", {}).get("streamSid")
                            print(f"üéß [Twilio] stream START sid={stream_sid}")

                        elif ev == "media":
                            # Œº-law base64 tal cual hacia OpenAI
                            ulaw_b64 = data["media"]["payload"]
                            await openai_ws.send(json.dumps({
                                "type": "input_audio_buffer.append",
                                "audio": ulaw_b64  # g711_ulaw base64
                            }))

                        elif ev == "stop":
                            print("üõë [Twilio] stream STOP (fin de la llamada)")
                            try:
                                await openai_ws.close()
                            except Exception:
                                pass
                            break
                except Exception as e:
                    print(f"‚ö†Ô∏è [Twilio‚ÜíOpenAI] Error: {e}")

            # ---- OpenAI -> Twilio ----
            async def openai_to_twilio():
                try:
                    async for raw in openai_ws:
                        try:
                            evt = json.loads(raw)
                        except Exception:
                            continue

                        t = evt.get("type")

                        # Logs √∫tiles (omitimos frames de audio para no inundar)
                        if t and t not in (
                            "response.audio.delta",
                            "response.output_audio.delta",
                            "input_audio_buffer.speech_started",
                            "input_audio_buffer.speech_stopped",
                        ):
                            print(f"‚ÑπÔ∏è [OpenAI] {t}")

                        # Al detectar fin de habla: commit + pedir respuesta
                        if t == "input_audio_buffer.speech_stopped":
                            await openai_ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
                            await openai_ws.send(json.dumps({"type": "response.create"}))

                        # Audio saliente (nombres var√≠an entre previews)
                        if t in ("response.audio.delta", "response.output_audio.delta"):
                            audio_b64 = evt.get("delta") or evt.get("audio")
                            if not audio_b64:
                                continue
                            await outbound_queue.put(audio_b64)

                except Exception as e:
                    print(f"‚ö†Ô∏è [OpenAI‚ÜíTwilio] Error: {e}")

            await asyncio.gather(twilio_to_openai(), openai_to_twilio())

            # Cerrar emisor ritmado
            if not sender_task.done():
                sender_task.cancel()
                try:
                    await sender_task
                except asyncio.CancelledError:
                    pass

    except Exception as e:
        import traceback
        print("‚ùå [OpenAI] Fallo al conectar:", e)
        traceback.print_exc()
    finally:
        print("üî¥ [Twilio] WebSocket CLOSED")

# ===== Debug m√≠nimo =====
@app.get("/whoami")
async def whoami(request: Request):
    # Devuelve el bot que se resolver√≠a para esta petici√≥n (√∫til para pruebas)
    slug = None
    if ALLOW_QUERY_OVERRIDE:
        q = dict(request.query_params)
        if "bot" in q and q["bot"].strip():
            slug = q["bot"].strip().lower()
    return {"bot": slug}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main_fastapi:app", host="0.0.0.0", port=PORT, reload=True)
